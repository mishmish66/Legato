{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from einops import einsum, pack, rearrange, repeat\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "\n",
    "from legato.nets import Perceptron, TransitionModel\n",
    "from legato.sampler import PBallSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from data.npz\n",
    "data = np.load(\"../data.npz\")\n",
    "indices = np.load(\"../trained_net_params/indices.npz\")\n",
    "train_indices, test_indices = indices[\"train_indices\"], indices[\"test_indices\"]\n",
    "\n",
    "observations_train = data[\"observations\"][train_indices]\n",
    "actions_train = data[\"actions\"][train_indices]\n",
    "\n",
    "observations_test = torch.tensor(data[\"observations\"][test_indices], dtype=torch.float32, device=\"cuda\")\n",
    "actions_test = torch.tensor(data[\"actions\"][test_indices], dtype=torch.float32, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "state_encoder = torch.load(\"../trained_net_params/state_encoder.pt\")\n",
    "action_encoder = torch.load(\"../trained_net_params/action_encoder.pt\")\n",
    "transition_model = torch.load(\"../trained_net_params/transition_model.pt\")\n",
    "state_decoder = torch.load(\"../trained_net_params/state_decoder.pt\")\n",
    "action_decoder = torch.load(\"../trained_net_params/action_decoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_states = rearrange(observations_test, \"... f -> (...) f\")\n",
    "flat_actions = rearrange(actions_test, \"... f -> (...) f\")\n",
    "\n",
    "# SHuffle\n",
    "flat_states = flat_states[np_rng.permutation(flat_states.shape[0])]\n",
    "flat_actions = flat_actions[np_rng.permutation(flat_actions.shape[0])]\n",
    "\n",
    "flat_states = flat_states[:2048]\n",
    "flat_actions = flat_actions[:2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stdev of encoded states and actions across each element\n",
    "with torch.no_grad():\n",
    "    encoded_states = state_encoder(flat_states)\n",
    "    state_std = torch.std(encoded_states, dim=0)\n",
    "\n",
    "    encoded_actions = action_encoder((flat_actions, flat_states))\n",
    "\n",
    "    recovered_states = state_decoder(encoded_states)\n",
    "    recovered_actions = action_decoder((encoded_actions, encoded_states))\n",
    "\n",
    "    action_std = torch.std(encoded_actions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"State std: {state_std.cpu().numpy()}\\nAction std: {action_std.cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_batch_size = 32\n",
    "# Test forward model\n",
    "traj_inds = torch.randint(\n",
    "    0, observations_test.shape[0], (transition_batch_size,), device=\"cuda\"\n",
    ")\n",
    "test_start_inds = torch.randint(\n",
    "    0, int(observations_test.shape[-2] // 1.1), (transition_batch_size,), device=\"cuda\"\n",
    ")\n",
    "\n",
    "test_states = observations_test[traj_inds]\n",
    "test_actions = actions_test[traj_inds]\n",
    "\n",
    "start_states = observations_test[traj_inds, test_start_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_start_states = state_encoder(start_states)\n",
    "\n",
    "latent_traj_actions = action_encoder((test_actions, test_states))\n",
    "\n",
    "latent_pred_fut_states = transition_model(\n",
    "    latent_start_states, latent_traj_actions, start_indices=test_start_inds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_fut_states = state_encoder(test_states)\n",
    "\n",
    "traj_ind = traj_inds[0]\n",
    "start_ind = test_start_inds[0]\n",
    "\n",
    "latent_fut_states_select = latent_fut_states[0, start_ind:]\n",
    "latent_pred_fut_states_select = latent_pred_fut_states[0, start_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([latent_fut_states_select, latent_pred_fut_states_select], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure error per time into the future\n",
    "\n",
    "time_into_future = torch.arange(\n",
    "    latent_fut_states.shape[-2], device=\"cuda\"\n",
    ")[None] - test_start_inds[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_errors = torch.mean(\n",
    "    torch.abs(latent_fut_states - latent_pred_fut_states), dim=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_errors_flat = rearrange(mae_errors, \"... -> (...)\").detach().cpu().numpy()\n",
    "time_into_future_flat = (\n",
    "    rearrange(time_into_future, \"... -> (...)\").detach().cpu().numpy()\n",
    ")\n",
    "\n",
    "df = pandas.DataFrame.from_dict(\n",
    "    {\"mae_error\": mae_errors_flat, \"time_into_future\": time_into_future_flat},\n",
    ")\n",
    "df = df[df[\"time_into_future\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(data=df, x=\"time_into_future\", y=\"mae_error\", ax=ax)\n",
    "ax.set_xlim(0, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_state_sampler = PBallSampler(\n",
    "    4, 1, 2.0, device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_states = state_encoder(flat_states[:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoverageLoss(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_sampler,\n",
    "        norm_p=1,\n",
    "        latent_samples=2048,\n",
    "        selection_tail_size=4,\n",
    "        far_sample_count=64,\n",
    "        pushing_sample_size=4,\n",
    "        loss_function=nn.L1Loss(),  # nn.HuberLoss(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_sampler = latent_sampler\n",
    "        self.norm_p = norm_p\n",
    "        self.latent_samples = latent_samples\n",
    "        self.selection_tail_size = selection_tail_size\n",
    "        self.far_sample_count = far_sample_count\n",
    "        self.pushing_sample_size = pushing_sample_size\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def forward(self, latents):\n",
    "        # penalize for empty space within the state space\n",
    "        # Sample random points in the latent space\n",
    "\n",
    "        proposals = self.latent_sampler(self.latent_samples)\n",
    "        points = torch.cat([proposals, latents], dim=0)\n",
    "        distances = torch.cdist(proposals, points, p=self.norm_p)\n",
    "\n",
    "        in_point_mask = torch.zeros(\n",
    "            len(points), dtype=torch.bool, device=latents.device\n",
    "        )\n",
    "        in_point_mask[self.latent_samples :] = True\n",
    "        in_point_mask[self.latent_samples :] = True\n",
    "        far_samples = torch.zeros(\n",
    "            self.far_sample_count,\n",
    "            latents.shape[-1],\n",
    "            dtype=latents.dtype,\n",
    "            device=latents.device,\n",
    "        )\n",
    "        for i in range(self.far_sample_count):\n",
    "            in_point_dists = distances[:, in_point_mask]\n",
    "            tail_distances = torch.topk(\n",
    "                in_point_dists, self.selection_tail_size, dim=-1, largest=False\n",
    "            ).values.mean(-1)\n",
    "            # Mask out already selected points\n",
    "            tail_distances[in_point_mask[: self.latent_samples]] = -torch.inf\n",
    "            farthest_index = torch.topk(tail_distances, 1, dim=-1).indices\n",
    "            in_point_mask[farthest_index] = True\n",
    "            far_samples[i] = proposals[farthest_index]\n",
    "\n",
    "        # Now make the states by the latent states closer to the farthest samples\n",
    "        empty_space_dists = torch.cdist(far_samples, latents, p=self.norm_p)\n",
    "        close_empty_space_dists = torch.topk(\n",
    "            empty_space_dists, self.pushing_sample_size, dim=-1, largest=False\n",
    "        ).values.mean(-1)\n",
    "        space_coverage_loss = self.loss_function(\n",
    "            close_empty_space_dists, torch.zeros_like(close_empty_space_dists)\n",
    "        ).mean()\n",
    "\n",
    "        return far_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scl = CoverageLoss(latent_state_sampler, norm_p=1, latent_samples=16_384, selection_tail_size=4, far_sample_count=64, pushing_sample_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "far_samples = scl(latent_states)\n",
    "sdf = pandas.DataFrame.from_records(\n",
    "    np.concatenate(\n",
    "        [\n",
    "            np.concatenate(\n",
    "                [\n",
    "                    latent_states.detach().cpu().numpy(),\n",
    "                    np.zeros((len(latent_states), 1)),\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            np.concatenate(\n",
    "                [\n",
    "                    far_samples.detach().cpu().numpy(),\n",
    "                    np.ones((len(far_samples), 1)),\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    columns=[\"e0\", \"e1\", \"e2\", \"e3\", \"samp\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(sdf, hue=\"samp\", palette=\"icefire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_action_sampler = PBallSampler(\n",
    "    2, 1, 1.0, device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_actions = action_encoder((flat_actions[:512], flat_states[:512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl = CoverageLoss(latent_action_sampler, norm_p=1, latent_samples=16_384, selection_tail_size=4, far_sample_count=64, pushing_sample_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "far_samples = acl(latent_actions)\n",
    "adf = pandas.DataFrame.from_records(\n",
    "    np.concatenate(\n",
    "        [\n",
    "            np.concatenate(\n",
    "                [\n",
    "                    latent_actions.detach().cpu().numpy(),\n",
    "                    np.zeros((len(latent_actions), 1)),\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            np.concatenate(\n",
    "                [\n",
    "                    far_samples.detach().cpu().numpy(),\n",
    "                    np.ones((len(far_samples), 1)),\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    columns=[\"e0\", \"e1\", \"samp\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(adf, hue=\"samp\", palette=\"icefire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legato_simple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
