{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gymnasium as gym\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from stuff import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mujoco to use EGL\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "state_encoder = torch.load('trained_net_params/state_encoder.pt')\n",
    "action_encoder = torch.load('trained_net_params/action_encoder.pt')\n",
    "transiton_model = torch.load('trained_net_params/transition_model.pt')\n",
    "state_decoder = torch.load('trained_net_params/state_decoder.pt')\n",
    "action_decoder = torch.load('trained_net_params/action_decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from data.npz\n",
    "data = np.load(\"data.npz\")\n",
    "torchify = lambda *xs: [torch.tensor(x, dtype=torch.float32, device=\"cuda\") for x in xs]\n",
    "# torchify = lambda *xs: [torch.tensor(x, dtype=torch.float32) for x in xs]\n",
    "observations, actions = torchify(data[\"observations\"], data[\"actions\"])\n",
    "# observations, actions = observations[:4096], actions[:4096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space_size = 1.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's optimize a trajectory\n",
    "\n",
    "actions = torch.randn(32, 64, 2, device=\"cuda\")\n",
    "actions = actions / torch.norm(actions, p=1, dim=-1, keepdim=True)\n",
    "actions = actions * torch.rand((32, 64, 1), device=\"cuda\") * action_space_size\n",
    "\n",
    "actor = ActorPolicy(\n",
    "    2,\n",
    "    action_space_size,\n",
    "    state_encoder,\n",
    "    transiton_model,\n",
    "    action_decoder,\n",
    "    horizon=128,\n",
    "    iters=32,\n",
    ").cuda()\n",
    "\n",
    "env = gym.make(\"PointMaze_Large-v3\", render_mode=\"rgb_array\")\n",
    "obs, info = env.reset()\n",
    "state = torch.tensor(obs[\"observation\"], dtype=torch.float32, device=\"cuda\")\n",
    "latent_action_plan = None\n",
    "\n",
    "initial_state = state\n",
    "target_state = torch.tensor(\n",
    "    [*obs[\"desired_goal\"], 0, 0], dtype=torch.float32, device=\"cuda\"\n",
    ")\n",
    "\n",
    "actions = []\n",
    "states = [initial_state]\n",
    "\n",
    "frames = [env.render()]\n",
    "for i in tqdm(range(1024), disable=True):\n",
    "    next_action, latent_action_plan = actor(\n",
    "        state[None], target_state[None], latent_action_plan\n",
    "    )\n",
    "    obs, rew, term, trunc, info = env.step(next_action[0].cpu().numpy())\n",
    "    state = torch.tensor(obs[\"observation\"], dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "    actions.append(next_action[0].cpu().numpy())\n",
    "    states.append(state)\n",
    "\n",
    "    frames.append(env.render())\n",
    "    print(f\"Iteration {i}, action: {next_action[0].cpu().numpy()}\")\n",
    "\n",
    "traj_actions = torch.tensor(actions, dtype=torch.float32, device=\"cuda\")\n",
    "traj_states = torch.stack(states, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the video\n",
    "media.show_video(frames, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_traj_states = state_encoder(traj_states)\n",
    "latent_traj_actions = action_encoder(torch.cat([traj_actions, latent_traj_states[..., 1:, :]], dim=-1))\n",
    "latent_initial_state = state_encoder(initial_state[None])\n",
    "\n",
    "predicted_fut_latent_states = transiton_model(latent_initial_state, latent_traj_actions[None])\n",
    "predicted_fut_states = state_decoder(predicted_fut_latent_states)\n",
    "actual_fut_states = traj_states[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_fut_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_fut_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legato_simple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
