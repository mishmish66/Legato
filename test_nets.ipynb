{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from einops import einsum, pack, rearrange, repeat\n",
    "from torch import nn\n",
    "\n",
    "from nets import Perceptron, TransitionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from data.npz\n",
    "data = np.load(\"data.npz\")\n",
    "indices = np.load(\"trained_net_params/indices.npz\")\n",
    "train_indices, test_indices = indices[\"train_indices\"], indices[\"test_indices\"]\n",
    "\n",
    "observations_train = data[\"observations\"][train_indices]\n",
    "actions_train = data[\"actions\"][train_indices]\n",
    "\n",
    "observations_test = torch.tensor(data[\"observations\"][test_indices], dtype=torch.float32, device=\"cuda\")\n",
    "actions_test = torch.tensor(data[\"actions\"][test_indices], dtype=torch.float32, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "state_encoder = torch.load(\"trained_net_params/state_encoder.pt\")\n",
    "action_encoder = torch.load(\"trained_net_params/action_encoder.pt\")\n",
    "transition_model = torch.load(\"trained_net_params/transition_model.pt\")\n",
    "state_decoder = torch.load(\"trained_net_params/state_decoder.pt\")\n",
    "action_decoder = torch.load(\"trained_net_params/action_decoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_states = rearrange(observations_test, \"... f -> (...) f\")\n",
    "flat_actions = rearrange(actions_test, \"... f -> (...) f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stdev of encoded states and actions across each element\n",
    "with torch.no_grad():\n",
    "    encoded_states = state_encoder(flat_states)\n",
    "    state_std = torch.std(encoded_states, dim=0)\n",
    "\n",
    "    encoded_actions = action_encoder(torch.cat([flat_actions, flat_states], dim=-1))\n",
    "\n",
    "    recovered_states = state_decoder(encoded_states)\n",
    "    recovered_actions = action_decoder(\n",
    "        torch.cat([encoded_actions, encoded_states], dim=-1)\n",
    "    )\n",
    "\n",
    "    action_std = torch.std(encoded_actions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State std: [0.18352377 0.19787525 0.20208438 0.08535806]\n",
      "Action std: [0.94992095 0.91848886]\n"
     ]
    }
   ],
   "source": [
    "print(f\"State std: {state_std.cpu().numpy()}\\nAction std: {action_std.cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_batch_size = 32\n",
    "# Test forward model\n",
    "traj_inds = torch.randint(\n",
    "    0, observations_test.shape[0], (transition_batch_size,), device=\"cuda\"\n",
    ")\n",
    "test_start_inds = torch.randint(\n",
    "    0, int(observations_test.shape[-2] // 1.1), (transition_batch_size,), device=\"cuda\"\n",
    ")\n",
    "\n",
    "test_states = observations_test[traj_inds]\n",
    "test_actions = actions_test[traj_inds]\n",
    "\n",
    "start_states = observations_test[traj_inds, test_start_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_start_states = state_encoder(start_states)\n",
    "\n",
    "latent_traj_actions = action_encoder(torch.cat([test_actions, test_states], dim=-1))\n",
    "\n",
    "latent_pred_fut_states = transition_model(\n",
    "    latent_start_states, latent_traj_actions, start_indices=test_start_inds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(605, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_fut_states = state_encoder(test_states) \n",
    "\n",
    "traj_ind = traj_inds[0]\n",
    "start_ind = test_start_inds[0]\n",
    "\n",
    "latent_fut_states_select = latent_fut_states[0, start_ind :]\n",
    "latent_pred_fut_states_select = latent_pred_fut_states[0, start_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0056, -0.1353,  0.1802,  0.0828],\n",
       "         [-0.0273, -0.1289,  0.1737,  0.0794],\n",
       "         [-0.0239, -0.1289,  0.1636,  0.0794],\n",
       "         ...,\n",
       "         [ 0.0614, -0.0443, -0.0229, -0.0284],\n",
       "         [ 0.0567, -0.0472, -0.0299, -0.0350],\n",
       "         [ 0.0453, -0.0462, -0.0243, -0.0392]], device='cuda:0',\n",
       "        grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.0015, -0.1084, -0.0285,  0.0764],\n",
       "         [-0.0230, -0.1141, -0.0157,  0.0792],\n",
       "         [ 0.0030, -0.1120, -0.0202,  0.0749],\n",
       "         ...,\n",
       "         [ 0.0334, -0.0987, -0.0442,  0.0651],\n",
       "         [ 0.0142, -0.0876, -0.0324,  0.0685],\n",
       "         [ 0.0044, -0.0965, -0.0246,  0.0701]], device='cuda:0',\n",
       "        grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_fut_states_select, latent_pred_fut_states_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legato_simple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
