{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from einops import einsum, pack, rearrange, repeat\n",
    "from torch import nn\n",
    "\n",
    "from stuff import Perceptron, TransitionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from data.npz\n",
    "data = np.load('data.npz')\n",
    "torchify = lambda *xs: [torch.tensor(x, dtype=torch.float32, device='cuda') for x in xs]\n",
    "# torchify = lambda *xs: [torch.tensor(x, dtype=torch.float32) for x in xs]\n",
    "observations, actions = torchify(data['observations'], data['actions'])\n",
    "# observations, actions = observations[:4096], actions[:4096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define networks\n",
    "\n",
    "state_dim = observations.shape[-1]\n",
    "action_dim = actions.shape[-1]\n",
    "\n",
    "state_encoder = Perceptron(state_dim, [32, 64, 32], state_dim).cuda()\n",
    "action_encoder = Perceptron(action_dim + state_dim, [32, 32, 32], action_dim).cuda()\n",
    "transition_model = TransitionModel(2, 4, 64).cuda()\n",
    "state_decoder = Perceptron(state_dim, [32, 64, 32], state_dim).cuda()\n",
    "action_decoder = Perceptron(action_dim + state_dim, [32, 32, 32], action_dim).cuda()\n",
    "\n",
    "nets = [\n",
    "    state_encoder,\n",
    "    action_encoder,\n",
    "    transition_model,\n",
    "    state_decoder,\n",
    "    action_decoder,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionLoss(nn.Module):\n",
    "    def __init__(self, loss_fn=nn.MSELoss()):\n",
    "        super().__init__()\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, latent_fut_states_prime, latent_fut_states_gt, mask):\n",
    "        masked_latent_fut_states_prime = torch.where(\n",
    "            mask[..., None], latent_fut_states_gt, latent_fut_states_prime\n",
    "        )\n",
    "        loss = self.loss_fn(masked_latent_fut_states_prime, latent_fut_states_gt)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothnessLoss(nn.Module):\n",
    "    def __init__(self, norm_p=1, discount=0.99):\n",
    "        super().__init__()\n",
    "        self.discount = discount\n",
    "        self.norm_p = norm_p\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        latent_actions,\n",
    "        latent_next_states,\n",
    "        latent_actions_perturbed,\n",
    "        latent_next_states_perturbed,\n",
    "        mask,\n",
    "    ):\n",
    "        action_diffs = latent_actions_perturbed - latent_actions\n",
    "        action_dists = torch.norm(action_diffs, p=self.norm_p, dim=-1)\n",
    "\n",
    "        state_diffs = latent_next_states_perturbed - latent_next_states\n",
    "        state_dists = torch.norm(state_diffs, p=self.norm_p, dim=-1)\n",
    "\n",
    "        future_indices = torch.cumsum(~mask, dim=-1, dtype=torch.float32)\n",
    "        future_discounts = self.discount**future_indices\n",
    "        dist_limits = action_dists / future_discounts\n",
    "        state_violations = torch.relu(state_dists - dist_limits)\n",
    "        losses = state_violations**2\n",
    "        masked_losses = torch.where(mask, 0, losses)\n",
    "\n",
    "        return masked_losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoverageLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_space_size,\n",
    "        action_space_size,\n",
    "        latent_samples=2048,\n",
    "        space_ball_p=1,\n",
    "        selection_tail_size=4,\n",
    "        far_sample_count=64,\n",
    "        pushing_sample_size=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.state_space_size = state_space_size\n",
    "        self.action_space_size = action_space_size\n",
    "\n",
    "        self.latent_samples = latent_samples\n",
    "        self.space_ball_p = space_ball_p\n",
    "        self.selection_tail_size = selection_tail_size\n",
    "        self.far_sample_count = far_sample_count\n",
    "        self.pushing_sample_size = pushing_sample_size\n",
    "\n",
    "    def forward(self, latent_states, latent_actions):\n",
    "        latent_states = rearrange(latent_states, \"... e -> (...) e\")\n",
    "        latent_actions = rearrange(latent_actions, \"... e -> (...) e\")\n",
    "\n",
    "        state_norms = torch.norm(latent_states, p=self.space_ball_p, dim=-1)\n",
    "        action_norms = torch.norm(latent_actions, p=self.space_ball_p, dim=-1)\n",
    "\n",
    "        state_violations = torch.relu(state_norms - self.state_space_size)\n",
    "        action_violations = torch.relu(action_norms - self.action_space_size)\n",
    "\n",
    "        state_size_violations = state_violations**2\n",
    "        action_size_violations = action_violations**2\n",
    "\n",
    "        state_size_loss = state_size_violations.mean()\n",
    "        action_size_loss = action_size_violations.mean()\n",
    "\n",
    "        # penalize for empty space within the state space\n",
    "        # Sample random points in the latent space\n",
    "        if self.space_ball_p != 1:\n",
    "            raise NotImplementedError(\"Only L1 norm is supported :(\")\n",
    "\n",
    "        state_space_samples = (\n",
    "            torch.rand(\n",
    "                self.latent_samples,\n",
    "                latent_states.shape[-1],\n",
    "                device=latent_states.device,\n",
    "            )\n",
    "            * 2\n",
    "            - 1\n",
    "        ) * self.state_space_size\n",
    "        action_space_samples = (\n",
    "            torch.rand(\n",
    "                self.latent_samples,\n",
    "                latent_actions.shape[-1],\n",
    "                device=latent_actions.device,\n",
    "            )\n",
    "            * 2\n",
    "            - 1\n",
    "        ) * self.action_space_size\n",
    "\n",
    "        # Find the state_space that is the farthest from any of the latent_states\n",
    "        state_space_dists = torch.cdist(state_space_samples, latent_states, p=1)\n",
    "        state_space_dist_tail = (\n",
    "            state_space_dists.sort(dim=-1)\n",
    "            .values[:, : self.selection_tail_size]\n",
    "            .mean(dim=-1)\n",
    "        )\n",
    "        farthest_idxs = state_space_dist_tail.argsort(descending=True)[\n",
    "            : self.far_sample_count\n",
    "        ]\n",
    "        farthest_state_samples = state_space_samples[farthest_idxs]\n",
    "\n",
    "        action_space_dists = torch.cdist(action_space_samples, latent_actions, p=1)\n",
    "        action_space_dist_tail = (\n",
    "            action_space_dists.sort(dim=-1)\n",
    "            .values[:, : self.selection_tail_size]\n",
    "            .mean(dim=-1)\n",
    "        )\n",
    "        farthest_idxs = action_space_dist_tail.argsort(descending=True)[\n",
    "            : self.far_sample_count\n",
    "        ]\n",
    "        farthest_action_samples = action_space_samples[farthest_idxs]\n",
    "\n",
    "        # Now make the states by the farthest latent states closer to the farthest samples\n",
    "        # Maybe in the future make just the few closest ones closer\n",
    "        empty_state_space_dists = torch.cdist(\n",
    "            farthest_state_samples, latent_states, p=1\n",
    "        )\n",
    "        close_empty_state_space_dists = empty_state_space_dists.sort(dim=-1).values[\n",
    "            :, : self.pushing_sample_size\n",
    "        ]\n",
    "        state_coverage_losses = close_empty_state_space_dists**2\n",
    "\n",
    "        empty_action_space_dists = torch.cdist(\n",
    "            farthest_action_samples, latent_actions, p=1\n",
    "        )\n",
    "        close_empty_action_space_dists = empty_action_space_dists.sort(dim=-1).values[\n",
    "            :, : self.pushing_sample_size\n",
    "        ]\n",
    "        action_coverage_losses = close_empty_action_space_dists**2\n",
    "\n",
    "        return (\n",
    "            state_size_loss\n",
    "            + action_size_loss\n",
    "            + state_coverage_losses.mean()\n",
    "            + action_coverage_losses.mean()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_mse = nn.MSELoss()\n",
    "state_mse = nn.MSELoss()\n",
    "transition_loss_func = TransitionLoss()\n",
    "\n",
    "smoothness_loss_func = SmoothnessLoss()\n",
    "\n",
    "coverage_loss_func = torch.compile(\n",
    "    CoverageLoss(\n",
    "        state_space_size=1.5,\n",
    "        action_space_size=1.75,\n",
    "        latent_samples=16_384,\n",
    "        # latent_state_samples=1024,\n",
    "        # latent_action_samples=1024,\n",
    "    )\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [param for net in nets for param in net.parameters()], lr=1e-2\n",
    ")\n",
    "# lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "#     optimizer, start_factor=1, end_factor=1e-2, total_iters=1024\n",
    "# )\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer,\n",
    "    gamma=0.995,\n",
    "    last_epoch=-1,\n",
    ")\n",
    "\n",
    "encoder_batch_size = 4096\n",
    "transition_batch_size = 32\n",
    "\n",
    "for i in range(1024):\n",
    "\n",
    "    # Yoink a batch of data\n",
    "    encoder_batch_raveled_inds = torch.randperm(np.prod(observations.shape[:-1]))[\n",
    "        :encoder_batch_size\n",
    "    ]\n",
    "    encoder_batch_inds = torch.unravel_index(\n",
    "        encoder_batch_raveled_inds, observations.shape[:-1]\n",
    "    )\n",
    "\n",
    "    transition_traj_batch_inds = torch.randperm(observations.shape[0], device=\"cuda\")[\n",
    "        :transition_batch_size\n",
    "    ]\n",
    "    transition_start_inds = torch.randint(\n",
    "        0, int(observations.shape[-2] // 1.1), (transition_batch_size,), device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    state_batch = observations[encoder_batch_inds]\n",
    "    action_batch = actions[encoder_batch_inds]\n",
    "\n",
    "    starting_states = observations[transition_traj_batch_inds, transition_start_inds]\n",
    "    state_traj_batch = observations[transition_traj_batch_inds]\n",
    "    action_traj_batch = actions[transition_traj_batch_inds]\n",
    "\n",
    "    # Now do a forward pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    latent_states = state_encoder(state_batch)\n",
    "    latent_actions = action_encoder(torch.cat([action_batch, state_batch], dim=-1))\n",
    "\n",
    "    reconstructed_states = state_decoder(latent_states)\n",
    "    reconstructed_actions = action_decoder(\n",
    "        torch.cat([latent_actions, latent_states], dim=-1)\n",
    "    )\n",
    "\n",
    "    state_reconstruction_loss = state_mse(reconstructed_states, state_batch)\n",
    "    action_reconstruction_loss = action_mse(reconstructed_actions, action_batch)\n",
    "\n",
    "    latent_start_states = state_encoder(starting_states).detach()\n",
    "    latent_traj_actions = action_encoder(\n",
    "        torch.cat([action_traj_batch, state_traj_batch], dim=-1)\n",
    "    ).detach()\n",
    "    latent_fut_states_prime, mask = transition_model(\n",
    "        latent_start_states,\n",
    "        latent_traj_actions,\n",
    "        start_indices=transition_start_inds,\n",
    "        return_mask=True,\n",
    "    )\n",
    "    latent_fut_states_gt = state_encoder(state_traj_batch)\n",
    "\n",
    "    perturbations = torch.randn_like(latent_traj_actions)\n",
    "    perturbations = perturbations / torch.norm(perturbations, p=1, dim=-1, keepdim=True)\n",
    "    perturbations = perturbations * torch.rand(\n",
    "        (*perturbations.shape[:-1], 1), device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    latent_traj_actions_perturbed = latent_traj_actions + perturbations\n",
    "    # Normalize the perturbations if they are too large\n",
    "    perturbed_action_norms = torch.norm(\n",
    "        latent_traj_actions_perturbed, p=1, dim=-1, keepdim=True\n",
    "    )\n",
    "    latent_traj_actions_perturbed = torch.where(\n",
    "        perturbed_action_norms > coverage_loss_func.action_space_size,\n",
    "        latent_traj_actions_perturbed\n",
    "        * coverage_loss_func.action_space_size\n",
    "        / perturbed_action_norms,\n",
    "        latent_traj_actions_perturbed,\n",
    "    )\n",
    "    latent_fut_states_prime_perturbed = transition_model(\n",
    "        latent_start_states,\n",
    "        latent_traj_actions_perturbed,\n",
    "        start_indices=transition_start_inds,\n",
    "    )\n",
    "\n",
    "    transition_loss = transition_loss_func(\n",
    "        latent_fut_states_prime, latent_fut_states_gt, mask\n",
    "    )\n",
    "    smoothness_loss = smoothness_loss_func(\n",
    "        latent_traj_actions,\n",
    "        latent_fut_states_prime,\n",
    "        latent_traj_actions_perturbed,\n",
    "        latent_fut_states_prime_perturbed,\n",
    "        mask,\n",
    "    )\n",
    "    coverage_loss = coverage_loss_func(latent_states, latent_actions)\n",
    "\n",
    "    loss = (\n",
    "        state_reconstruction_loss\n",
    "        + action_reconstruction_loss\n",
    "        + transition_loss * 0.1\n",
    "        + smoothness_loss\n",
    "        + coverage_loss * 0.01\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    if i % 64 == 0:\n",
    "        print(\n",
    "            f\"Iteration {i}, total loss: {loss.item()}, lr: {lr_scheduler.get_last_lr()}, transition loss: {transition_loss.item()}, smoothness loss: {smoothness_loss.item()}, coverage loss: {coverage_loss.item()}, state reconstruction loss: {state_reconstruction_loss.item()}, action reconstruction loss: {action_reconstruction_loss.item()}\"\n",
    "        )\n",
    "\n",
    "# Delete everything related to optimization\n",
    "optimizer.zero_grad()\n",
    "del optimizer\n",
    "del lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Networks\n",
    "\n",
    "torch.save(state_encoder, \"trained_net_params/state_encoder.pt\")\n",
    "torch.save(action_encoder, \"trained_net_params/action_encoder.pt\")\n",
    "torch.save(transition_model, \"trained_net_params/transition_model.pt\")\n",
    "torch.save(state_decoder, \"trained_net_params/state_decoder.pt\")\n",
    "torch.save(action_decoder, \"trained_net_params/action_decoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stdev of encoded states and actions across each element\n",
    "with torch.no_grad():\n",
    "    encoded_states = rearrange(state_encoder(observations), \"... e -> (...) e\")\n",
    "    state_std = torch.std(encoded_states, dim=0)\n",
    "\n",
    "    encoded_actions = rearrange(\n",
    "        action_encoder(torch.cat([actions, observations], dim=-1)), \"... e -> (...) e\"\n",
    "    )\n",
    "    \n",
    "    recovered_states = state_decoder(encoded_states)\n",
    "    recovered_actions = action_decoder(torch.cat([encoded_actions, encoded_states], dim=-1))\n",
    "    \n",
    "    action_std = torch.std(encoded_actions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_std, action_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(\n",
    "    tensor([0.4034, 0.8038, 0.6741, 0.7653], device=\"cuda:0\"),\n",
    "    tensor([1.0077, 1.0054], device=\"cuda:0\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_states - rearrange(observations, \"... e -> (...) e\"), recovered_actions - rearrange(actions, \"... e -> (...) e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([recovered_states, rearrange(observations, \"... e -> (...) e\")], dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legato_simple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
